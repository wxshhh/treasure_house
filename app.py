"""ä¸ªäººçŸ¥è¯†åº“ç³»ç»Ÿä¸»åº”ç”¨å…¥å£"""

import os
import time
import streamlit as st
import pandas as pd
from typing import List, Dict, Any, Optional, Callable

# å¯¼å…¥é…ç½®å’Œæ¨¡å—
from config import APP_CONFIG, DOCUMENT_DIR, DOCUMENT_CONFIG
from src.document_processor import PDFProcessor, WordProcessor, TextProcessor, URLProcessor
from src.vector_store import ChromaStore
from src.model import create_llm, SentenceEmbedding
from src.utils.helpers import get_document_processor, get_file_extension, get_file_size_str

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "documents" not in st.session_state:
    st.session_state.documents = []

# æ·»åŠ åˆ·æ–°æ ‡è®°
if "need_refresh" not in st.session_state:
    st.session_state.need_refresh = False

# ç¡®ä¿embedding_modelåœ¨åˆå§‹åŒ–åå†è°ƒç”¨load_model
if "embedding_model" not in st.session_state:
    st.session_state.embedding_model = SentenceEmbedding()
    # å°†load_model()è°ƒç”¨ç§»åˆ°åˆå§‹åŒ–ä¹‹åçš„å•ç‹¬æ£€æŸ¥ä¸­

# ç¡®ä¿åœ¨embedding_modelåˆå§‹åŒ–åå†åˆå§‹åŒ–vector_store
if "vector_store" not in st.session_state:
    # ç¡®ä¿embedding_modelå·²ç»åˆå§‹åŒ–
    if "embedding_model" in st.session_state:
        st.session_state.vector_store = ChromaStore(embedding_function=st.session_state.embedding_model.encode)
    else:
        st.error("åˆå§‹åŒ–å‘é‡å­˜å‚¨å¤±è´¥ï¼šåµŒå…¥æ¨¡å‹æœªåˆå§‹åŒ–")

# åœ¨æ‰€æœ‰åˆå§‹åŒ–å®Œæˆåï¼ŒåŠ è½½æ¨¡å‹
if "embedding_model" in st.session_state and st.session_state.embedding_model is not None:
    try:
        st.session_state.embedding_model.load_model()
    except Exception as e:
        st.error(f"åŠ è½½åµŒå…¥æ¨¡å‹å¤±è´¥: {str(e)}")

if "model" not in st.session_state:
    st.session_state.model = None
if "use_llm" not in st.session_state:
    st.session_state.use_llm = False

# é‡ç½®çŸ¥è¯†åº“çš„äºŒæ¬¡ç¡®è®¤
if "confirm_reset" not in st.session_state:
    st.session_state.confirm_reset = False

# è¿›åº¦ç®¡ç†ç›¸å…³å¸¸é‡
PROCESS_STAGES = {
    "save_file": {"weight": 0.1, "desc": "ä¿å­˜æ–‡ä»¶"},
    "init_processor": {"weight": 0.1, "desc": "åˆå§‹åŒ–å¤„ç†å™¨"},
    "extract_metadata": {"weight": 0.2, "desc": "æå–å…ƒæ•°æ®"},
    "process_content": {"weight": 0.4, "desc": "å¤„ç†å†…å®¹"},
    "generate_chunks": {"weight": 0.1, "desc": "ç”Ÿæˆæ–‡æœ¬å—"},
    "vector_store": {"weight": 0.1, "desc": "å†™å…¥å‘é‡åº“"}
}

def init_progress():
    """åˆå§‹åŒ–è¿›åº¦çŠ¶æ€"""
    st.session_state.progress = {
        "current": 0,
        "current_stage": "",
        "stages": PROCESS_STAGES
    }

def update_progress(stage_name: str, progress: float):
    """æ›´æ–°è¿›åº¦å›è°ƒå‡½æ•°"""
    if not isinstance(stage_name, str):
        raise TypeError(f"stage_name must be a string, got {type(stage_name)}")
        
    if stage_name not in st.session_state.progress["stages"]:
          raise ValueError(f"Invalid stage name: {stage_name}. Valid stages are: {list(st.session_state.progress['stages'].keys())}")
        
    stage = st.session_state.progress["stages"][stage_name]
    stage_keys = list(st.session_state.progress["stages"].keys())
    try:
        stage_index = stage_keys.index(stage_name)
        base_progress = sum(
            st.session_state.progress["stages"][k]["weight"]
            for k in stage_keys[:stage_index]
        )
    except ValueError as e:
        raise ValueError(f"Stage '{stage_name}' not found in progress stages") from e
    
    current_progress = base_progress + progress * stage["weight"]
    st.session_state.progress["current"] = current_progress
    st.session_state.progress["current_stage"] = stage["desc"]

def handle_error(error: Exception, message: str) -> None:
    """ç»Ÿä¸€é”™è¯¯å¤„ç†"""
    st.error(f"{message}: {str(error)}")
    if 'progress' in st.session_state:
        del st.session_state.progress

def format_metadata(metadata: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–æ–‡æ¡£å…ƒæ•°æ®"""
    formatted = []
    if metadata.get('source_type') == 'url':
        # URLç±»å‹å…ƒæ•°æ®
        if metadata.get('url'):
            formatted.append(f"**URL**: {metadata['url']}")
        formatted.append(f"**æ¥æº**: ç½‘é¡µ")
    else:
        # æ–‡æ¡£ç±»å‹å…ƒæ•°æ®
        if metadata.get('title'):
            formatted.append(f"**æ ‡é¢˜**: {metadata['title']}")
        if metadata.get('author'):
            formatted.append(f"**ä½œè€…**: {metadata['author']}")
        if metadata.get('created'):
            formatted.append(f"**åˆ›å»ºæ—¶é—´**: {metadata['created']}")
        if metadata.get('file_size'):
            formatted.append(f"**å¤§å°**: {get_file_size_str(metadata['file_size'])}")
    return "\n".join(formatted)

def process_document(uploaded_file):
    """å¤„ç†ä¸Šä¼ çš„æ–‡æ¡£"""
    try:
        print("å¼€å§‹å¤„ç†æ–‡æ¡£:", uploaded_file.name)
        # ä¿å­˜ä¸Šä¼ æ–‡ä»¶
        file_path = os.path.join(DOCUMENT_DIR, uploaded_file.name)
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        print("æ–‡ä»¶å·²ä¿å­˜åˆ°:", file_path)
        
        # è·å–æ–‡æ¡£å¤„ç†å™¨
        processor = get_document_processor(file_path)
        print("æ–‡æ¡£å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ:", type(processor).__name__)
        
        # åˆå§‹åŒ–è¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        progress_data = {"current": 0, "stage": ""}

        # å®šä¹‰è¿›åº¦æ›´æ–°å›è°ƒï¼ˆåœ¨ä¸»çº¿ç¨‹æ‰§è¡Œï¼‰
        def update_ui():
            progress_bar.progress(progress_data["current"])
            status_text.text(f"{progress_data['stage']} ({int(progress_data['current']*100)}%)")

        # è®¾ç½®å¤„ç†å™¨è¿›åº¦å›è°ƒï¼ˆåå°çº¿ç¨‹è°ƒç”¨ï¼‰
        def progress_callback(stage_name, progress):
            # æ›´æ–°å…±äº«è¿›åº¦æ•°æ®
            try:
                print(f"è¿›åº¦å›è°ƒ: stage_name={stage_name}, progress={progress}")
                stage_keys = list(PROCESS_STAGES.keys())
                # æ£€æŸ¥stage_nameæ˜¯å¦åœ¨PROCESS_STAGESä¸­
                if stage_name in PROCESS_STAGES:
                    stage_index = stage_keys.index(stage_name)
                    base_progress = sum(
                        PROCESS_STAGES[k]["weight"]
                        for k in stage_keys[:stage_index]
                    )
                    current_progress = base_progress + progress * PROCESS_STAGES[stage_name]["weight"]
                    stage_desc = PROCESS_STAGES[stage_name]["desc"]
                    print(f"è¿›åº¦è®¡ç®—: base_progress={base_progress}, current_progress={current_progress}, stage_desc={stage_desc}")
                else:
                    # å¦‚æœstage_nameä¸åœ¨PROCESS_STAGESä¸­ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    current_progress = progress
                    stage_desc = stage_name
                    print(f"æœªçŸ¥é˜¶æ®µ: {stage_name}, ä½¿ç”¨é»˜è®¤è¿›åº¦å€¼: {progress}")
                
                progress_data.update({
                    "current": current_progress,
                    "stage": stage_desc
                })
                print(f"æ›´æ–°è¿›åº¦æ•°æ®: current={current_progress}, stage={stage_desc}")
                # ç›´æ¥æ›´æ–°UIï¼Œä¸ä½¿ç”¨experimental_rerun()
                print("ç›´æ¥æ›´æ–°UIï¼Œä¸ä½¿ç”¨experimental_rerun()")
                update_ui()
            except Exception as e:
                print(f"Progress callback error: {str(e)}")
                # ç»§ç»­å¤„ç†ï¼Œä¸ä¸­æ–­æ–‡æ¡£å¤„ç†æµç¨‹

        processor.set_progress_callback(progress_callback)
        
        # å¯åŠ¨æ–‡æ¡£å¤„ç†
        processor.process(file_path)
        update_ui()  # æœ€åæ›´æ–°ä¸€æ¬¡è¿›åº¦
        
        
        result = processor.get_result()
        if result is None:
            raise Exception("æ–‡æ¡£å¤„ç†å¤±è´¥")
            
        return result
        
    except Exception as e:
        handle_error(e, "æ–‡æ¡£å¤„ç†å¤±è´¥")
        return None

def add_to_vector_store(document_data):
    """å°†æ–‡æ¡£æ·»åŠ åˆ°å‘é‡å­˜å‚¨"""
    chunks = document_data["chunks"]
    source = document_data["source"]
    metadata = document_data["metadata"]
    
    metadatas = []
    for i, chunk in enumerate(chunks):
        chunk_metadata = metadata.copy()
        chunk_metadata["chunk_index"] = i
        chunk_metadata["chunk_count"] = len(chunks)
        chunk_metadata["source"] = source
        metadatas.append(chunk_metadata)
    
    try:
        ids = st.session_state.vector_store.add_texts(chunks, metadatas)
        return ids
    except Exception as e:
        handle_error(e, "æ·»åŠ åˆ°å‘é‡å­˜å‚¨å¤±è´¥")
        return []

def search_documents(query, top_k=5):
    """æœç´¢æ–‡æ¡£"""
    try:
        results = st.session_state.vector_store.similarity_search(
            query, 
            k=top_k,
            use_llm=st.session_state.use_llm
        )
        return results
    except Exception as e:
        handle_error(e, "æœç´¢å¤±è´¥")
        return []

def generate_answer(query, context):
    """ç”Ÿæˆå›ç­”"""
    if st.session_state.model is None:
        load_model()
    
    try:
        answer = st.session_state.model.generate_response(query, context)
        return answer
    except Exception as e:
        return f"ç”Ÿæˆå›ç­”å¤±è´¥: {str(e)}"

def format_search_results(results):
    """æ ¼å¼åŒ–æœç´¢ç»“æœä¸ºå¯è¯»æ–‡æœ¬"""
    if not results:
        return ""
    
    formatted_text = ""
    for i, result in enumerate(results):
        # è·³è¿‡LLMç”Ÿæˆçš„ç»“æœ
        if result['metadata'].get('source') == 'LLM':
            continue
            
        formatted_text += f"### ç›¸ä¼¼ç‰‡æ®µ {i+1} (ç›¸ä¼¼åº¦: {result['score']:.2f})\n"
        
        # æ ¹æ®æ¥æºç±»å‹æ˜¾ç¤ºä¸åŒå…ƒæ•°æ®
        if result.get('source_type') == 'url':
            formatted_text += f"**æ¥æº**: ç½‘ç»œé“¾æ¥ğŸ”—\n"
            if 'url' in result['metadata']:
                formatted_text += f"**URL**: {result['metadata']['url']}\n"
        else:
            formatted_text += f"**æ¥æº**: {result['metadata'].get('source', 'æœªçŸ¥')}\n"
            if 'title' in result['metadata']:
                formatted_text += f"**æ ‡é¢˜**: {result['metadata']['title']}\n"
        
        # æ·»åŠ æ–‡æ¡£ä½ç½®ä¿¡æ¯
        if 'chunk_index' in result['metadata'] and 'chunk_count' in result['metadata']:
            formatted_text += f"**ä½ç½®**: ç¬¬ {result['metadata']['chunk_index'] + 1}/{result['metadata']['chunk_count']} æ®µ\n"
        
        # æ·»åŠ æ–‡æ¡£ç‰¹å®šå…ƒæ•°æ®
        if 'page_count' in result['metadata']:
            formatted_text += f"**æ€»é¡µæ•°**: {result['metadata']['page_count']}\n"
        
        # æ˜¾ç¤ºç›¸ä¼¼æ–‡æœ¬ç‰‡æ®µ
        formatted_text += f"\n**ç›¸å…³å†…å®¹**:\n{result['content']}\n\n"
    
    return formatted_text
    
    return formatted_text

def load_model():
    """åŠ è½½å¤§æ¨¡å‹"""
    if st.session_state.model is None:
        with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹ï¼Œè¯·ç¨å€™..."):
            st.session_state.model = create_llm()
            st.session_state.model.generate_response("ä½ å¥½")

def process_url(url: str) -> Dict[str, Any]:
    """å¤„ç†ç½‘é¡µé“¾æ¥"""
    try:
        print("å¼€å§‹å¤„ç†ç½‘é¡µé“¾æ¥:", url)
        # åˆå§‹åŒ–URLå¤„ç†å™¨
        processor = URLProcessor()
        
        # åˆå§‹åŒ–è¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        progress_data = {"current": 0, "stage": ""}

        # å®šä¹‰è¿›åº¦æ›´æ–°å›è°ƒï¼ˆåœ¨ä¸»çº¿ç¨‹æ‰§è¡Œï¼‰
        def update_ui():
            progress_bar.progress(progress_data["current"])
            status_text.text(f"{progress_data['stage']} ({int(progress_data['current']*100)}%)")

        # è®¾ç½®å¤„ç†å™¨è¿›åº¦å›è°ƒï¼ˆåå°çº¿ç¨‹è°ƒç”¨ï¼‰
        def progress_callback(stage_name, progress):
            try:
                print(f"è¿›åº¦å›è°ƒ: stage_name={stage_name}, progress={progress}")
                stage_keys = list(PROCESS_STAGES.keys())
                if stage_name in PROCESS_STAGES:
                    stage_index = stage_keys.index(stage_name)
                    base_progress = sum(
                        PROCESS_STAGES[k]["weight"]
                        for k in stage_keys[:stage_index]
                    )
                    current_progress = base_progress + progress * PROCESS_STAGES[stage_name]["weight"]
                    stage_desc = PROCESS_STAGES[stage_name]["desc"]
                    print(f"è¿›åº¦è®¡ç®—: base_progress={base_progress}, current_progress={current_progress}, stage_desc={stage_desc}")
                else:
                    current_progress = progress
                    stage_desc = stage_name
                    print(f"æœªçŸ¥é˜¶æ®µ: {stage_name}, ä½¿ç”¨é»˜è®¤è¿›åº¦å€¼: {progress}")
                
                progress_data.update({
                    "current": current_progress,
                    "stage": stage_desc
                })
                print(f"æ›´æ–°è¿›åº¦æ•°æ®: current={current_progress}, stage={stage_desc}")
                update_ui()
            except Exception as e:
                print(f"Progress callback error: {str(e)}")

        processor.set_progress_callback(progress_callback)
        
        # å¤„ç†ç½‘é¡µé“¾æ¥
        result = processor.process_url(url)
        update_ui()  # æœ€åæ›´æ–°ä¸€æ¬¡è¿›åº¦
        
        if result is None:
            raise Exception("ç½‘é¡µé“¾æ¥å¤„ç†å¤±è´¥")
            
        return result
        
    except Exception as e:
        handle_error(e, "ç½‘é¡µé“¾æ¥å¤„ç†å¤±è´¥")
        return None

def render_document_management():
    """æ¸²æŸ“æ–‡æ¡£ç®¡ç†ç•Œé¢"""
    st.header("æ–‡æ¡£ç®¡ç†")
    
    # åˆ›å»ºä¸¤ä¸ªé€‰é¡¹å¡ï¼šä¸Šä¼ æ–‡æ¡£å’Œç½‘é¡µé“¾æ¥
    tab1, tab2 = st.tabs(["ä¸Šä¼ æ–‡æ¡£", "ç½‘é¡µé“¾æ¥"])
    
    # ä¸Šä¼ æ–‡æ¡£é€‰é¡¹å¡
    with tab1:
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æ–‡æ¡£", 
            type=[ext.replace(".", "") for ext in DOCUMENT_CONFIG["supported_formats"]],
            help="æ”¯æŒPDFã€Wordå’ŒTXTæ ¼å¼"
        )
    
    # ç½‘é¡µé“¾æ¥é€‰é¡¹å¡
    with tab2:
        url = st.text_input(
            "ç½‘é¡µé“¾æ¥",
            placeholder="è¯·è¾“å…¥ç½‘é¡µé“¾æ¥ï¼Œä¾‹å¦‚ï¼šhttps://r.jina.ai/https://zhuanlan.zhihu.com/p/xxxxxx",
            help="æ”¯æŒä»»ä½•ç½‘é¡µé“¾æ¥"
        )
    
    if uploaded_file is not None:
        if st.button("å¤„ç†æ–‡æ¡£", key="process_doc"):
            document_data = process_document(uploaded_file)
            
            if document_data:
                print("add_to_vector_store")
                ids = add_to_vector_store(document_data)
                
                if ids:
                    st.session_state.documents.append({
                        "name": uploaded_file.name,
                        "path": os.path.join(DOCUMENT_DIR, uploaded_file.name),
                        "metadata": document_data["metadata"],
                        "total_chunks": len(document_data["chunks"]),
                        "ids": ids
                    })
                    st.success(f"æ–‡æ¡£ '{uploaded_file.name}' å¤„ç†æˆåŠŸï¼Œå·²æ·»åŠ åˆ°çŸ¥è¯†åº“")
    
    if url:
        if st.button("å¤„ç†é“¾æ¥", key="process_url"):
            document_data = process_url(url)
            
            if document_data:
                print("add_to_vector_store")
                ids = add_to_vector_store(document_data)
                
                if ids:
                    st.session_state.documents.append({
                        "url": url,
                        "metadata": document_data["metadata"],
                        "total_chunks": len(document_data["chunks"]),
                        "ids": ids
                    })
                    st.success(f"é“¾æ¥ '{url}' å¤„ç†æˆåŠŸï¼Œå·²æ·»åŠ åˆ°çŸ¥è¯†åº“")
    
    if st.session_state.documents:
        st.subheader("å·²æ·»åŠ çš„æ–‡æ¡£")
        for i, doc in enumerate(st.session_state.documents):
            with st.expander(f"{i+1}. {doc.get('name', doc.get('url', 'æœªçŸ¥'))}", expanded=False):
                st.write(format_metadata(doc['metadata']))
                st.write(f"**åˆ†å—æ•°**: {doc['total_chunks']}")
                if st.button("åˆ é™¤", key=f"delete_{i}"):
                    st.session_state.vector_store.delete(doc['ids'])
                    st.session_state.documents.pop(i)
                    st.success(f"æ–‡æ¡£ '{doc.get('name', doc.get('url', 'æœªçŸ¥'))}' å·²åˆ é™¤")
                    st.experimental_rerun()
    else:
        st.info("å°šæœªæ·»åŠ ä»»ä½•æ–‡æ¡£")
    
    st.subheader("çŸ¥è¯†åº“ç»Ÿè®¡")
    doc_count = len(st.session_state.documents)
    chunk_count = st.session_state.vector_store.count()
    st.metric("æ–‡æ¡£æ•°é‡", doc_count)
    st.metric("æ–‡æœ¬å—æ•°é‡", chunk_count)

    if not st.session_state.confirm_reset:
        if st.button("é‡ç½®çŸ¥è¯†åº“", type="primary", help="æ¸…ç©ºæ‰€æœ‰æ–‡æ¡£å’Œå‘é‡å­˜å‚¨"):
            st.session_state.confirm_reset = True
            st.experimental_rerun()
    else:
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ç¡®è®¤é‡ç½®", type="primary"):
                if st.session_state.documents or st.session_state.vector_store.count() > 0:
                    st.session_state.vector_store.reset()
                    st.session_state.documents = []
                    st.success("çŸ¥è¯†åº“å·²é‡ç½®")
                else:
                    st.warning("çŸ¥è¯†åº“ä¸ºç©ºï¼Œæ— éœ€é‡ç½®")
                st.session_state.confirm_reset = False
                st.experimental_rerun()
        with col2:
            if st.button("å–æ¶ˆ", type="secondary"):
                st.session_state.confirm_reset = False
                st.experimental_rerun()

def render_qa_interface():
    """æ¸²æŸ“é—®ç­”ç•Œé¢"""
    st.header("çŸ¥è¯†åº“é—®ç­”")
    
    # æ·»åŠ LLMå¼€å…³
    st.session_state.use_llm = st.checkbox(
        "ä½¿ç”¨å¤§æ¨¡å‹å¢å¼ºæœç´¢",
        value=st.session_state.use_llm,
        help="å¯ç”¨åï¼Œæœç´¢ç»“æœå°†åŒ…å«å¤§æ¨¡å‹ç”Ÿæˆçš„å¢å¼ºå›ç­”"
    )
    
    query = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜", placeholder="ä¾‹å¦‚ï¼šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")
    col1, col2 = st.columns([1, 4])
    with col1:
        top_k = st.number_input("æ£€ç´¢æ–‡æ¡£æ•°é‡", min_value=1, max_value=10, value=3)
    with col2:
        search_btn = st.button("æœç´¢", type="primary", help="ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£")
    
    if query and search_btn:
        results = search_documents(query, top_k=top_k)
        
        if results:
            with st.expander("æ£€ç´¢ç»“æœ", expanded=True):
                st.markdown(format_search_results(results))
                
            # ä¸è°ƒç”¨å¤§æ¨¡å‹
            if not st.session_state.use_llm:
                return
            
            context = "\n\n".join([result["content"] for result in results])
            
            with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
                answer = generate_answer(query, context)
                
            st.subheader("å›ç­”")
            st.markdown(answer)
        else:
            st.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œè¯·å°è¯•å…¶ä»–é—®é¢˜æˆ–æ·»åŠ æ›´å¤šæ–‡æ¡£åˆ°çŸ¥è¯†åº“")

def render_document_browser():
    """æ¸²æŸ“æ–‡æ¡£æµè§ˆç•Œé¢"""
    st.header("æ–‡æ¡£æµè§ˆ")
    
    if st.session_state.documents:
        doc_data = []
        for doc in st.session_state.documents:
            print("doc:", doc)
            metadata = doc["metadata"]
            row = {
                "åç§°": doc.get("matedata", {}).get("title") if doc.get("source_type") == "file" else metadata.get("url", ""),
                "ç±»å‹": "ç½‘ç»œé“¾æ¥" if doc.get("url") !=  "" else "ä¸Šä¼ æ–‡ä»¶",
                "åˆ†å—æ•°": doc["total_chunks"]
            }
            
            if doc.get('source_type', "file") == 'url':
                row["URL"] = metadata.get('url', '')
            else:
                row.update({
                    "å¤§å°": get_file_size_str(metadata.get("file_size", 0)),
                    "åˆ›å»ºæ—¶é—´": metadata.get("created", ""),
                    "ä½œè€…": metadata.get("author", "æœªçŸ¥")
                })
            
            doc_data.append(row)
        
        st.dataframe(pd.DataFrame(doc_data), use_container_width=True)
    else:
        st.info("å°šæœªæ·»åŠ ä»»ä½•æ–‡æ¡£ï¼Œè¯·åœ¨ä¾§è¾¹æ ä¸Šä¼ æ–‡æ¡£")

def main():
    """ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title=APP_CONFIG["title"],
        page_icon=APP_CONFIG["icon"],
        layout="wide"
    )
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°é¡µé¢
    if st.session_state.get("need_refresh", False):
        st.session_state.need_refresh = False
        st.experimental_rerun()
        return
    
    st.title(APP_CONFIG["title"])
    st.markdown(APP_CONFIG["description"])

    # ä¾§è¾¹æ  - æ–‡æ¡£ç®¡ç†
    with st.sidebar:
        render_document_management()

    # ä¸»åŒºåŸŸ - çŸ¥è¯†åº“é—®ç­”
    tabs = st.tabs(["çŸ¥è¯†åº“é—®ç­”", "æ–‡æ¡£æµè§ˆ"])

    with tabs[0]:
        render_qa_interface()

    with tabs[1]:
        render_document_browser()

    # é¡µè„š
    st.markdown("---")
    st.markdown("ğŸ“š ä¸ªäººçŸ¥è¯†åº“ç³»ç»Ÿ | æœ¬åœ°åŒ–éƒ¨ç½² | æ•°æ®éšç§ä¿æŠ¤")

if __name__ == "__main__":
    main()
